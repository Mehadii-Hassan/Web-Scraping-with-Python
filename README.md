<h1 align="center">🕸️ Web Scraping with Python</h1> 

<p align="center">
  <strong>A complete journey of learning and practicing Web Scraping</strong><br>
  Built using <code>Requests</code>, <code>BeautifulSoup</code>, <code>Selenium</code>, and <code>Excel</code> integration 🚀
</p>

<hr>

<h2>📌 Project Overview</h2>

<p>
This repository contains my personal practice codes for <strong>Web Scraping with Python</strong>.  
It starts from basic HTML parsing and goes up to advanced tasks like scraping dynamic pages,  
handling login-protected data, and checking malware domains with <strong>VirusTotal</strong>.  
Each step is a small project that makes the learning process structured and fun.
</p>

<ul>
  <li>✅ Beginner-friendly step-by-step scripts</li>
  <li>🌐 Covers static & dynamic scraping</li>
  <li>📑 Save results into CSV and Excel</li>
  <li>🛡️ Includes malware detection & data storage</li>
</ul>

<hr>

<h2>🎯 Goals</h2>

<ul>
  <li>🌱 Learn practical web scraping with Python</li>
  <li>💡 Work with BeautifulSoup & Selenium</li>
  <li>📊 Store scraped data into CSV/Excel files</li>
  <li>🛠️ Build real-world automation scripts</li>
</ul>

<hr>

<h2>📂 Files in this Repository</h2>

<ul>
  <li>📄 <code>step1_get_html.py</code> → Fetch raw HTML</li>
  <li>📄 <code>step2_parse_html.py</code> → Parse HTML with BeautifulSoup</li>
  <li>📄 <code>step3_find_first_quote.py</code> → Extract first quote</li>
  <li>📄 <code>step4_extract_text_author.py</code> → Extract quote + author</li>
  <li>📄 <code>step5_loop_all_quotes.py</code> → Loop through all quotes</li>
  <li>📄 <code>step6_save_to_csv.py</code> → Save data to CSV</li>
  <li>📄 <code>step7_save_to_excel.py</code> → Save data to Excel</li>
  <li>📄 <code>step8_scrape_multiple_pages.py</code> → Scrape multiple pages</li>
  <li>📄 <code>step9_scrape_login_protected_data.py</code> → Scrape login-protected pages</li>
  <li>📄 <code>step10_selenium_dynamic.py</code> → Handle dynamic pages with Selenium</li>
  <li>📄 <code>step11_login_then_scrape_using_selenium.py</code> → Login & scrape with Selenium</li>
  <li>📄 <code>step12_scrape_multiple_pages.py</code> → Multi-page scraping with Selenium</li>
  <li>📄 <code>contact_scraper.py</code> → Scrape contact info</li>
  <li>📄 <code>virustotal_check.py</code> → Check websites for malware (VirusTotal API)</li>
  <li>📄 <code>save_excel.py</code> → Save scraped results into Excel</li>
  <li>📑 <code>websites.txt</code> → List of websites to check</li>
  <li>📑 <code>infected_websites.xlsx</code> → Malware check results</li>
</ul>

<hr>

<h2>🙌 Credits</h2>

<p>
Maintained by <strong>Mehadi Hassan</strong> ✨  
</p>

<hr>

<p align="center">⭐ If you find this repo useful, don't forget to star it!</p>
